{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference_humanpose.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanLehner/Colab-collection/blob/master/inference_humanpose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khQWI6eplfAq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMFFYJ6Clf4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# crashes with AttributeError: module 'keras.engine.topology' has no attribute 'load_weights_from_hdf5_group_by_name'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pijyug9dlf9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "47cec9b0-f0fa-43b5-e1c4-af06a665fba0"
      },
      "source": [
        "# https://github.com/Superlee506/Mask_RCNN_Humanpose\n",
        "# Python 3.5+\n",
        "!pip install tensorflow==1.4.1\n",
        "!pip install keras==2.0.8\n",
        "# Jupyter Notebook\n",
        "!pip install numpy \n",
        "!pip install scikit-image \n",
        "!pip install scipy \n",
        "!pip install Pillow \n",
        "!pip install cython\n",
        "!pip install h5py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.4.1 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (1.16.3)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (3.7.1)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (1.1.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.1) (0.33.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.1) (3.1)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.1) (1.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.1) (0.15.2)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.1) (0.9999999)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.4.1) (41.0.1)\n",
            "Requirement already satisfied: keras==2.0.8 in /usr/local/lib/python3.6/dist-packages (2.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.16.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.14.2)\n",
            "Requirement already satisfied: dask[array]>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.5)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (0.6.1)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.2.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.12.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.0.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (4.3.0)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=1.0.0->scikit-image) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.11.0; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=1.0.0->scikit-image) (1.16.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image) (4.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-image) (41.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fOFOW0yl_Cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e89d662-c97e-4409-dcd3-a3ee534487be"
      },
      "source": [
        "# clone repo\n",
        "%cd /content/\n",
        "import os\n",
        "from os.path import exists, join, basename\n",
        "\n",
        "project_name = \"Mask_RCNN_Humanpose\"\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q https://github.com/Superlee506/Mask_RCNN_Humanpose.git\n",
        "  #!cd $project_name && pip install -q -r requirements.txt\n",
        "  \n",
        "import sys\n",
        "sys.path.append(project_name)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srtsV_QzlgBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "0e31237c-60fe-4c84-e5e5-e153a2f09b96"
      },
      "source": [
        "!wget https://github.com/Superlee506/Mask_RCNN_Humanpose/releases/download/v0.9-alpha/mask_rcnn_coco_humanpose.h5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-14 13:54:58--  https://github.com/Superlee506/Mask_RCNN_Humanpose/releases/download/v0.9-alpha/mask_rcnn_coco_humanpose.h5\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/122574850/b894f976-31db-11e8-8e0c-602a8864f382?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190514%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190514T135459Z&X-Amz-Expires=300&X-Amz-Signature=19e14e286636a5a238fdc695e8a72f6d5c9cea7e6dbce54921163930bfa5be6d&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco_humanpose.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-05-14 13:54:59--  https://github-production-release-asset-2e65be.s3.amazonaws.com/122574850/b894f976-31db-11e8-8e0c-602a8864f382?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190514%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190514T135459Z&X-Amz-Expires=300&X-Amz-Signature=19e14e286636a5a238fdc695e8a72f6d5c9cea7e6dbce54921163930bfa5be6d&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco_humanpose.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.18.240\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.18.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 326931832 (312M) [application/octet-stream]\n",
            "Saving to: ‘mask_rcnn_coco_humanpose.h5.1’\n",
            "\n",
            "mask_rcnn_coco_huma 100%[===================>] 311.79M  99.3MB/s    in 3.1s    \n",
            "\n",
            "2019-05-14 13:55:02 (99.3 MB/s) - ‘mask_rcnn_coco_humanpose.h5.1’ saved [326931832/326931832]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igGDeOhmlgRy",
        "colab_type": "text"
      },
      "source": [
        "# Mask R-CNN for Human Pose Estimation Demo\n",
        "\n",
        "A quick intro to using the pre-trained model to detect and segment objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfPBBkmjlfAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import coco\n",
        "import utils\n",
        "import model as modellib\n",
        "import visualize\n",
        "from model import log\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"mylogs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco_humanpose.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "COCO_DIR = \"D:/Github/FastMaskRCNN/data/coco\"  # TODO: enter value here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkNw4DqelfAz",
        "colab_type": "text"
      },
      "source": [
        "## Configurations\n",
        "\n",
        "Run one of the code blocks below to import and load the configurations to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "huRus48ClfA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "3bf8f020-9224-4ee0-f5d8-5c07cfe549e7"
      },
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    KEYPOINT_MASK_POOL_SIZE = 7\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "# model_path = model.find_last()[1]\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_coco_humanpose.h5\")\n",
        "# Load trained weights (fill in path to trained weights here)\n",
        "assert model_path != \"\", \"Provide path to trained weights\"\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights from  /content/mask_rcnn_coco_humanpose.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-56cbb141dafd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Provide path to trained weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Mask_RCNN_Humanpose/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.engine.topology' has no attribute 'load_weights_from_hdf5_group_by_name'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO_Ht0bQlfA5",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZJ7lXUklfA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "assert inference_config.NAME == \"coco\"\n",
        "# Training dataset\n",
        "#load person keypoints dataset\n",
        "train_dataset_keypoints = coco.CocoDataset(task_type=\"person_keypoints\")\n",
        "train_dataset_keypoints.load_coco(COCO_DIR, \"train\")\n",
        "train_dataset_keypoints.prepare() \n",
        "\n",
        "val_dataset_keypoints = coco.CocoDataset(task_type=\"person_keypoints\")\n",
        "val_dataset_keypoints.load_coco(COCO_DIR, \"val\")\n",
        "val_dataset_keypoints.prepare() \n",
        "\n",
        "print(\"Train Keypoints Image Count: {}\".format(len(train_dataset_keypoints.image_ids)))\n",
        "print(\"Train Keypoints Class Count: {}\".format(train_dataset_keypoints.num_classes))\n",
        "for i, info in enumerate(train_dataset_keypoints.class_info):\n",
        "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
        "    \n",
        "print(\"Val Keypoints Image Count: {}\".format(len(val_dataset_keypoints.image_ids)))\n",
        "print(\"Val Keypoints Class Count: {}\".format(val_dataset_keypoints.num_classes))\n",
        "for i, info in enumerate(val_dataset_keypoints.class_info):\n",
        "    print(\"{:3}. {:50}\".format(i, info['name']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sR3whaVlfA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(val_dataset_keypoints.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask, gt_keypoint =\\\n",
        "    modellib.load_image_gt_keypoints(val_dataset_keypoints, inference_config, \n",
        "                           image_id, augment=False,use_mini_mask=inference_config.USE_MINI_MASK)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "log(\"gt_keypoint\", gt_keypoint)\n",
        "visualize.display_keypoints(original_image,gt_bbox,gt_keypoint,gt_class_id,val_dataset_keypoints.class_names，skeleton = inference_config.LIMBS)\n",
        "if(inference_config.USE_MINI_MASK):\n",
        "    gt_mask = utils.expand_mask(gt_bbox,gt_mask,original_image.shape)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            val_dataset_keypoints.class_names,)\n",
        "\n",
        "# original_image, image_meta, gt_class_id, gt_bbox, gt_mask, gt_keypoint =\\\n",
        "#     modellib.load_image_gt_keypoints(val_dataset_keypoints, inference_config, \n",
        "#                            image_id, augment=True,use_mini_mask=inference_config.USE_MINI_MASK)\n",
        "\n",
        "# log(\"original_image\", original_image)\n",
        "# log(\"image_meta\", image_meta)\n",
        "# log(\"gt_class_id\", gt_class_id)\n",
        "# log(\"gt_bbox\", gt_bbox)\n",
        "# log(\"gt_mask\", gt_mask)\n",
        "# log(\"gt_keypoint\", gt_keypoint)\n",
        "# visualize.display_keypoints(original_image,gt_bbox,gt_keypoint,gt_class_id,val_dataset_keypoints.class_names)\n",
        "# if(inference_config.USE_MINI_MASK):\n",
        "#     gt_mask = utils.expand_mask(gt_bbox,gt_mask,original_image.shape)\n",
        "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "#                             val_dataset_keypoints.class_names,)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3_t6IVqlfBE",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6zvFA1VlfBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.detect_keypoint([original_image], verbose=0)\n",
        "\n",
        "r = results[0] # for one image\n",
        "\n",
        "log(\"rois\",r['rois'])\n",
        "log(\"keypoints\",r['keypoints'])\n",
        "log(\"class_ids\",r['class_ids'])\n",
        "log(\"keypoints\",r['keypoints'])\n",
        "log(\"masks\",r['masks'])\n",
        "\n",
        "visualize.display_keypoints(original_image,r['rois'],r['keypoints'],r['class_ids'],val_dataset_keypoints.class_names)\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            val_dataset_keypoints.class_names, r['scores'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KvbYkKplfBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}